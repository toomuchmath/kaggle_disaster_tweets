{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT-pytorch-disaster-tweets.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ae0e00326df148e9b1a2098c323ff692": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5c19064e00a9482d87602b8ae83e4ea5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_361bde7e5555406eb9aa6d49a20a58b9",
              "IPY_MODEL_66003184b00a4bed9e13c93e9c553353"
            ]
          }
        },
        "5c19064e00a9482d87602b8ae83e4ea5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "361bde7e5555406eb9aa6d49a20a58b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f17b3607bd204947b0a9d8aaa6584fc1",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd4ce7cf45804b1da26508aae1c8f408"
          }
        },
        "66003184b00a4bed9e13c93e9c553353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0fe1d433a72e410ca4a3c241175eacbc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 232k/232k [00:00&lt;00:00, 417kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_686f55f06f9f4deb9ceade3af45aff67"
          }
        },
        "f17b3607bd204947b0a9d8aaa6584fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd4ce7cf45804b1da26508aae1c8f408": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0fe1d433a72e410ca4a3c241175eacbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "686f55f06f9f4deb9ceade3af45aff67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2fe4502aabb48179de3ae090b78d68d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_23b24d77f9dd47ca8f475734e0dcf9c3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_69c487d960f44815a6d23d1d9b772dc8",
              "IPY_MODEL_9d8574697874408cbf6fe3b2375f4d07"
            ]
          }
        },
        "23b24d77f9dd47ca8f475734e0dcf9c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69c487d960f44815a6d23d1d9b772dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6e8e0214ab5943359d34c1d902c22872",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8344796386224ec9b3bab81fbaa2bae4"
          }
        },
        "9d8574697874408cbf6fe3b2375f4d07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2581a4208260492bbe8b610f8dff34fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 361/361 [00:00&lt;00:00, 11.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e60c409ccf54479a7947978756e0252"
          }
        },
        "6e8e0214ab5943359d34c1d902c22872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8344796386224ec9b3bab81fbaa2bae4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2581a4208260492bbe8b610f8dff34fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e60c409ccf54479a7947978756e0252": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1bb33f45da7b426aa673acf0efeec47c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fac5b8d1ae7b4a848d6411e26922a677",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8c0522815f0c431cafeed5696ed9e1f0",
              "IPY_MODEL_9faabd42f0b9448f8948354e271c983c"
            ]
          }
        },
        "fac5b8d1ae7b4a848d6411e26922a677": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c0522815f0c431cafeed5696ed9e1f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_056f0487e9e9495f9de68f1927230f9a",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3cffea91b7634ddf8ef09a1a85d21c24"
          }
        },
        "9faabd42f0b9448f8948354e271c983c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7e66cecb89ad4b4da79bafe30f2f9567",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 440M/440M [00:33&lt;00:00, 13.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da6facc354d840dcb3bcd66f280d48ac"
          }
        },
        "056f0487e9e9495f9de68f1927230f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3cffea91b7634ddf8ef09a1a85d21c24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e66cecb89ad4b4da79bafe30f2f9567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da6facc354d840dcb3bcd66f280d48ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1UXN9aNBmnN",
        "colab_type": "text"
      },
      "source": [
        "# Intro\n",
        "\n",
        "A little background story:\n",
        "\n",
        "I decided to take part in [this kaggle competition](https://www.kaggle.com/c/nlp-getting-started/overview) predicting whether a twitter tweet signals a real disaster. After a few rounds of data cleansing + preprocessing as well as trials with various models, I realised it was difficult to improve my model performance further - my best f1 score was 0.80061 and was achieved using Multinomial Naive Bayes.\n",
        "\n",
        "Back to this notebook, I would like to try transfer learning using PyTorch and see if it would give a good boost to the f1 score.\n",
        "\n",
        "Before starting, I came across some good resources and would like to mention them for they helped me a lot in getting started:\n",
        "1. [PyTorch Tutorial](https://pytorch.org/tutorials/intermediate/dynamic_quantization_bert_tutorial.html)\n",
        "2. [BERT Fine Tuning](https://mccormickml.com/2019/07/22/BERT-fine-tuning/)\n",
        "3. [PyTorch pretrained BERT](https://modelzoo.co/model/pytorch-pretrained-bert)\n",
        "\n",
        "tl;dr:\n",
        "Yes! It did improve my score. I am now at 0.82413. Not tremendous, I know, but my knowledge improved much more than my score did.\n",
        "\n",
        "My next step is to perform some sort of data augmentation to increase the training data size. The current (also the original) training data has 7613 rows, which isn't a lot. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjvdNFVVwKPw",
        "colab_type": "text"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Before I begin, I would like to download [transformers](https://github.com/huggingface/transformers) package by huggingface. It's a really useful library for tokenizing and training later but Colab doesn't have it installed. So let's do that manually. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4evRG7agXQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers\n",
        "# output from this cell has been omitted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sg5W4R77gfVF",
        "colab_type": "code",
        "outputId": "27d30e94-1553-4cc6-8964-bf6bddf03d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "# import all the libraries \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from transformers import BertModel, BertTokenizer, BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ayiXsG0G54J",
        "colab_type": "text"
      },
      "source": [
        "It's quite amazing that Google offers GPU for free. This notebook is run on Google Colab GPU. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOPuZ_-DiDs4",
        "colab_type": "code",
        "outputId": "6832175b-c882-42ea-d3b7-be0fa8e51dbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8yQWn57L4LN",
        "colab_type": "text"
      },
      "source": [
        "# Data\n",
        "\n",
        "I got my data from the competition page [data tab](https://www.kaggle.com/c/nlp-getting-started/data).\n",
        "\n",
        "Usual start, pandas to read csv and get our train data in a pandas dataframe. I usually print the shape and do `head()`, `tail()` or `sample()` just to have a sense of what the data looks like. Since I have had quite a thorough look at the data beforehand, I am excluding data exploration in this notebook. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1by2i_Gf77g",
        "colab_type": "code",
        "outputId": "2bdb4450-9598-4172-8c81-31a8ecb1089e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "source": [
        "# get train data\n",
        "path = \"/content/train.csv\"\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "# overview of data\n",
        "print(\"df shape: {}\".format(df.shape))\n",
        "df.sample(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df shape: (7613, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2487</th>\n",
              "      <td>3570</td>\n",
              "      <td>desolate</td>\n",
              "      <td>Lahti, Finland</td>\n",
              "      <td>A new favorite: Desolate 2 by r3do https://t.c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6691</th>\n",
              "      <td>9586</td>\n",
              "      <td>thunder</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The thunder shook my house woke my sister and ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7247</th>\n",
              "      <td>10377</td>\n",
              "      <td>weapons</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@kirstiealley @_AnimalAdvocate Or pay it for a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4644</th>\n",
              "      <td>6603</td>\n",
              "      <td>inundated</td>\n",
              "      <td>Land of Lincoln</td>\n",
              "      <td>@yahoocare perhaps you should change you name ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>663</th>\n",
              "      <td>958</td>\n",
              "      <td>blaze</td>\n",
              "      <td>Mo.City</td>\n",
              "      <td>@Beautiful_Juic1 just letting you know</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4765</th>\n",
              "      <td>6781</td>\n",
              "      <td>lightning</td>\n",
              "      <td>Elchilicitanierraversal</td>\n",
              "      <td>#NowPlaying 'The Lightning Strike' de Snow Pat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1524</th>\n",
              "      <td>2204</td>\n",
              "      <td>catastrophic</td>\n",
              "      <td>Lurking</td>\n",
              "      <td>Pretty much every time the audio dies on an au...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7517</th>\n",
              "      <td>10750</td>\n",
              "      <td>wreckage</td>\n",
              "      <td>Mumbai, Maharashtra</td>\n",
              "      <td>Wreckage 'Conclusively Confirmed' as From MH37...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2443</th>\n",
              "      <td>3508</td>\n",
              "      <td>derailment</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#news Madhya Pradesh Train Derailment: Village...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3111</th>\n",
              "      <td>4465</td>\n",
              "      <td>electrocuted</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@steveycheese99 @MapMyRun where you being elec...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ... target\n",
              "2487   3570  ...      0\n",
              "6691   9586  ...      1\n",
              "7247  10377  ...      0\n",
              "4644   6603  ...      0\n",
              "663     958  ...      0\n",
              "4765   6781  ...      0\n",
              "1524   2204  ...      0\n",
              "7517  10750  ...      1\n",
              "2443   3508  ...      1\n",
              "3111   4465  ...      0\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-OTgZGBMhz-",
        "colab_type": "text"
      },
      "source": [
        "I am performing a two-line preprocessing here. The reason for doing minimal preprocessing is to test how good BERT is, without interfering too much at initial stage. \n",
        "\n",
        "After a few rounds of experiments, I added a `clean()` function. It's quite an exhaustive list but I am pretty sure I will get back to it later to make it neater and more concise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M78nQHJllwD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# some simple preprocessing\n",
        "df[['keyword', 'location']] = df[['keyword', 'location']].fillna(\" \")\n",
        "df[\"tweets\"] = df[\"text\"] + \" \" + df[\"keyword\"] + \" \" + df[\"location\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6kYm5FIl163",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get our feature and target as arrays. \n",
        "tweets = df[\"tweets\"].values\n",
        "labels = df[\"target\"].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QzXRnueyoPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is quite an exhaustive list\n",
        "\n",
        "def clean(tweet):\n",
        "\n",
        "    tweet = tweet.lower()\n",
        "    tweet = re.sub(r\"https?://\\S+|www\\.\\S+\", \"http\", tweet)\n",
        "    tweet = re.sub(r\"<.*?>\", \"html\", tweet)\n",
        "\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                                   u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                                   u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                                   u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                                   u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                                   u\"\\U00002702-\\U000027B0\"\n",
        "                                   u\"\\U000024C2-\\U0001F251\"\n",
        "                                   \"]+\", flags=re.UNICODE)\n",
        "    tweet = emoji_pattern.sub(r\"\", tweet)\n",
        "\n",
        "    # special characters\n",
        "    tweet = re.sub(r\"\\x89Ã»_\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Ã»Ã²\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Ã»Ã³\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Ã»Ã¯when\", \"when\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Ã»Ã¯\", \"\", tweet)\n",
        "    tweet = re.sub(r\"China\\x89Ã»Âªs\", \"china's\", tweet)\n",
        "    tweet = re.sub(r\"let\\x89Ã»Âªs\", \"let's\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Ã»Ã·\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Ã»Âª\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Ã»\\x9d\", \"\", tweet)\n",
        "    tweet = re.sub(r\"Ã¥_\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Ã»Â¢\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Ã»Â¢Ã¥Ãª\", \"\", tweet)\n",
        "    tweet = re.sub(r\"fromÃ¥Ãªwounds\", \"from wounds\", tweet)\n",
        "    tweet = re.sub(r\"Ã¥Ãª\", \"\", tweet)\n",
        "    tweet = re.sub(r\"Ã¥Ã¨\", \"\", tweet)\n",
        "    tweet = re.sub(r\"japÃ¬_n\", \"japan\", tweet)    \n",
        "    tweet = re.sub(r\"Ã¬Â©\", \"e\", tweet)\n",
        "    tweet = re.sub(r\"Ã¥Â¨\", \"\", tweet)\n",
        "    tweet = re.sub(r\"suruÃ¬Â¤\", \"suruc\", tweet)\n",
        "    tweet = re.sub(r\"Ã¥Ã§\", \"\", tweet)\n",
        "    tweet = re.sub(r\"Ã¥Â£3million\", \"3 million\", tweet)\n",
        "    tweet = re.sub(r\"Ã¥Ã \", \"\", tweet)\n",
        "\n",
        "    tweet = re.sub(r\",\", \"\", tweet)\n",
        "    tweet = re.sub(r\"i'm\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
        "    tweet = re.sub(r\"i've\", \"I have\", tweet)\n",
        "    tweet = re.sub(r\"it's\", \"it is\", tweet)\n",
        "    tweet = re.sub(r\"they've\", \"they have\", tweet)\n",
        "    tweet = re.sub(r\"y'all\", \"you all\", tweet)\n",
        "    tweet = re.sub(r\"weren't\", \"were not\", tweet)\n",
        "    tweet = re.sub(r\"let's\", \"let us\", tweet)\n",
        "    tweet = re.sub(r\"can't\", \"cannot\", tweet)\n",
        "    \n",
        "    tweet = re.sub(r\"&gt;\", \">\", tweet)\n",
        "    tweet = re.sub(r\"&lt;\", \"<\", tweet)\n",
        "    tweet = re.sub(r\"&amp;\", \"&\", tweet)\n",
        "\n",
        "    # Typos, slang and informal abbreviations\n",
        "    tweet = re.sub(r\"hwy\", \"highway\", tweet)  \n",
        "    tweet = re.sub(r\"pkwy\", \"parkway\", tweet) \n",
        "    tweet = re.sub(r\"fvck\", \"fuck\", tweet)  \n",
        "    tweet = re.sub(r\"w/e\", \"whatever\", tweet)\n",
        "    tweet = re.sub(r\"w/\", \"with\", tweet)\n",
        "    tweet = re.sub(r\"usagov\", \"usa government\", tweet)\n",
        "    tweet = re.sub(r\"recentlu\", \"recently\", tweet)\n",
        "    tweet = re.sub(r\"ph0tos\", \"photos\", tweet)\n",
        "    tweet = re.sub(r\"amirite\", \"am I right\", tweet)\n",
        "    tweet = re.sub(r\"exp0sed\", \"exposed\", tweet)\n",
        "    tweet = re.sub(r\"<3\", \"love\", tweet)\n",
        "    tweet = re.sub(r\"amageddon\", \"armageddon\", tweet)\n",
        "    tweet = re.sub(r\"trfc\", \"traffic\", tweet)\n",
        "    tweet = re.sub(r\"16yr\", \"16 year\", tweet)\n",
        "    tweet = re.sub(r\"lmao\", \"laughing my ass off\", tweet) \n",
        "    tweet = re.sub(r\"2k\\d\\d\", \"20\"+ tweet[2:4], tweet)\n",
        "    tweet = re.sub(r\"clvlnd\", \"cleveland\", tweet)\n",
        "    \n",
        "    tweet = re.sub(r\"t's\", \"t is\", tweet)\n",
        "    tweet = re.sub(r\"n't\", \" not\", tweet)\n",
        "    tweet = re.sub(r\"'ve\", \" have\", tweet)\n",
        "    return tweet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5B56bHPk50L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# apply clean() function to all tweets\n",
        "tweets = [clean(tweet) for tweet in tweets]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIRgxizUzx6d",
        "colab_type": "text"
      },
      "source": [
        "# Getting Ready\n",
        "\n",
        "Making our tweets BERT-ready so that BERT could read it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hT5EAV2VmlKp",
        "colab_type": "code",
        "outputId": "0fcc31a5-cb42-4d68-a65f-408ba22549a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "ae0e00326df148e9b1a2098c323ff692",
            "5c19064e00a9482d87602b8ae83e4ea5",
            "361bde7e5555406eb9aa6d49a20a58b9",
            "66003184b00a4bed9e13c93e9c553353",
            "f17b3607bd204947b0a9d8aaa6584fc1",
            "dd4ce7cf45804b1da26508aae1c8f408",
            "0fe1d433a72e410ca4a3c241175eacbc",
            "686f55f06f9f4deb9ceade3af45aff67"
          ]
        }
      },
      "source": [
        "# Load the pretrained BERT tokenizer and encode all tweets \n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "input_ids = []\n",
        "\n",
        "for tweet in tweets:\n",
        "  encoded_tweet = tokenizer.encode(tweet, add_special_tokens=True)\n",
        "  input_ids.append(encoded_tweet)\n",
        "\n",
        "# display an example\n",
        "print(\"Original tweet: {}\".format(tweets[0]))\n",
        "print(\"Token IDs: {}\".format(input_ids[0]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae0e00326df148e9b1a2098c323ff692",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_widâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Original tweet: our deeds are the reason of this #earthquake may allah forgive us all    \n",
            "Token IDs: [101, 2256, 15616, 2024, 1996, 3114, 1997, 2023, 1001, 8372, 2089, 16455, 9641, 2149, 2035, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu5frYernPLR",
        "colab_type": "code",
        "outputId": "d44c3c26-b751-45cd-a0c4-52a02c022a4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Know what the max tweet length is\n",
        "print('Max tweet length: ', max([len(tweet_id) for tweet_id in input_ids]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max tweet length:  93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeDiK7rxobxH",
        "colab_type": "code",
        "outputId": "cd0f2bf9-9c52-4454-e6c0-1be7487d30c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# I created an arbitrary max_len for padding. 128 because it's the smallest (2^x) number.\n",
        "max_len = 128\n",
        "print(\"Padding all tweets to max length: {}\".format(max_len))\n",
        "\n",
        "# pad with value = 0 and behind the tweets (hence 'post')\n",
        "# alternatively, could use torch.nn.utils.rnn.pad_sequence()\n",
        "input_ids = pad_sequences(input_ids, maxlen=max_len, dtype='long', value=0,\n",
        "                          truncating='post', padding='post')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Padding all tweets to max length: 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XGxTCe1ppsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# attention masks are for BERT to differentiate which are real words and which are padded sequence\n",
        "# real words have IDs > 0 while paddings have IDs == 0\n",
        "# the attention masks should be 0 for padded sequence and 1 for real words\n",
        "\n",
        "attention_masks = []\n",
        "\n",
        "for encoded_tweet in input_ids:\n",
        "    att_mask = [int(token_id > 0) for token_id in encoded_tweet]\n",
        "\n",
        "    attention_masks.append(att_mask)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u0vLdeZp96k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting data: 80% for training and 20% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = \\\n",
        "        train_test_split(input_ids, labels, random_state=1729, test_size=0.2)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = \\\n",
        "        train_test_split(attention_masks, labels, random_state=1729, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq7mlUE7qR2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B0WK_QgqZ4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHtT1n6Q6pB0",
        "colab_type": "text"
      },
      "source": [
        "# Model and Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWznlVdGqspU",
        "colab_type": "code",
        "outputId": "82752b44-4b85-469d-9694-a062634cbbab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f2fe4502aabb48179de3ae090b78d68d",
            "23b24d77f9dd47ca8f475734e0dcf9c3",
            "69c487d960f44815a6d23d1d9b772dc8",
            "9d8574697874408cbf6fe3b2375f4d07",
            "6e8e0214ab5943359d34c1d902c22872",
            "8344796386224ec9b3bab81fbaa2bae4",
            "2581a4208260492bbe8b610f8dff34fa",
            "4e60c409ccf54479a7947978756e0252",
            "1bb33f45da7b426aa673acf0efeec47c",
            "fac5b8d1ae7b4a848d6411e26922a677",
            "8c0522815f0c431cafeed5696ed9e1f0",
            "9faabd42f0b9448f8948354e271c983c",
            "056f0487e9e9495f9de68f1927230f9a",
            "3cffea91b7634ddf8ef09a1a85d21c24",
            "7e66cecb89ad4b4da79bafe30f2f9567",
            "da6facc354d840dcb3bcd66f280d48ac"
          ]
        }
      },
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification \n",
        "# layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # 2 for binary classification  \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "    )\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2fe4502aabb48179de3ae090b78d68d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bb33f45da7b426aa673acf0efeec47c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSnu2pXF7QHu",
        "colab_type": "text"
      },
      "source": [
        "This [post](https://towardsdatascience.com/why-adamw-matters-736223f31b5d) explains quite well the difference between Adam and AdamW. It seems that AdamW performs better than the classic Adam optimizer. So I will use it here. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcX4OXpEq5aF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8hxb_B5D8Bn",
        "colab_type": "text"
      },
      "source": [
        "I have decided to use `epochs = 5` even though the recommended numbers are between 2 and 4. This is because I realised there was still room for improvement at the 4th epoch. If you scroll down to look at the graph for losses, you could tell that at the 5th epoch, the loss is less than that at the 4th epoch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzySLC4OrBt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of training epochs\n",
        "epochs = 5\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAn8E7P1rE1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper Functions\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "# Function to format elapsed time\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCjedK5b8LaU",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "\n",
        "The following training code is based on the `run_glue.py` script from huggingface, click [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128) for source."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvf62aw8rJU-",
        "colab_type": "code",
        "outputId": "4ade529e-4d57-43a4-8dd9-ff5f17bd9e8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, \n",
        "                                                                        len(train_dataloader), \n",
        "                                                                        elapsed))\n",
        "\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {:.4f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {:.4f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    191.    Elapsed: 0:00:51.\n",
            "  Batch    80  of    191.    Elapsed: 0:01:43.\n",
            "  Batch   120  of    191.    Elapsed: 0:02:34.\n",
            "  Batch   160  of    191.    Elapsed: 0:03:26.\n",
            "\n",
            "  Average training loss: 0.4507\n",
            "  Training epcoh took: 0:04:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.8112\n",
            "  Validation took: 0:00:21\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    191.    Elapsed: 0:00:51.\n",
            "  Batch    80  of    191.    Elapsed: 0:01:43.\n",
            "  Batch   120  of    191.    Elapsed: 0:02:34.\n",
            "  Batch   160  of    191.    Elapsed: 0:03:25.\n",
            "\n",
            "  Average training loss: 0.3228\n",
            "  Training epcoh took: 0:04:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.8177\n",
            "  Validation took: 0:00:21\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    191.    Elapsed: 0:00:51.\n",
            "  Batch    80  of    191.    Elapsed: 0:01:43.\n",
            "  Batch   120  of    191.    Elapsed: 0:02:34.\n",
            "  Batch   160  of    191.    Elapsed: 0:03:25.\n",
            "\n",
            "  Average training loss: 0.2431\n",
            "  Training epcoh took: 0:04:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.8101\n",
            "  Validation took: 0:00:21\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    191.    Elapsed: 0:00:51.\n",
            "  Batch    80  of    191.    Elapsed: 0:01:43.\n",
            "  Batch   120  of    191.    Elapsed: 0:02:34.\n",
            "  Batch   160  of    191.    Elapsed: 0:03:25.\n",
            "\n",
            "  Average training loss: 0.1782\n",
            "  Training epcoh took: 0:04:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.8101\n",
            "  Validation took: 0:00:21\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of    191.    Elapsed: 0:00:51.\n",
            "  Batch    80  of    191.    Elapsed: 0:01:43.\n",
            "  Batch   120  of    191.    Elapsed: 0:02:34.\n",
            "  Batch   160  of    191.    Elapsed: 0:03:25.\n",
            "\n",
            "  Average training loss: 0.1359\n",
            "  Training epcoh took: 0:04:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.8101\n",
            "  Validation took: 0:00:22\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyiWCMC_2VDK",
        "colab_type": "text"
      },
      "source": [
        "# Visualize Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39T2e1t2rNvq",
        "colab_type": "code",
        "outputId": "e4df6da1-5a4b-43c7-a09f-61f225d4fe8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "% matplotlib inline\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Znvfckcn2f7p",
        "colab_type": "text"
      },
      "source": [
        "# Predict\n",
        "\n",
        "I decided to go ahead and predict using test data from the competition. I am doing the same steps as in the previous sections on train and validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTlR5wVSOv5V",
        "colab_type": "code",
        "outputId": "fac3674e-f558-48f2-a2c3-0facae5c381d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "source": [
        "# Load test dataset into a pandas dataframe.\n",
        "test_df = pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "# Display the number of sentences.\n",
        "print('Number of tweets in test data: {:,}\\n'.format(test_df.shape[0]))\n",
        "\n",
        "test_df[['keyword', 'location']] = test_df[['keyword', 'location']].fillna(\" \")\n",
        "test_df[\"tweets\"] = test_df[\"text\"] + \" \" + test_df[\"keyword\"] + \" \" + test_df[\"location\"]\n",
        "test_df"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of tweets in test data: 3,263\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>10861</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>EARTHQUAKE SAFETY LOS ANGELES Â‰Ã›Ã’ SAFETY FASTE...</td>\n",
              "      <td>EARTHQUAKE SAFETY LOS ANGELES Â‰Ã›Ã’ SAFETY FASTE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3259</th>\n",
              "      <td>10865</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
              "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>10868</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
              "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>10874</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
              "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>10875</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
              "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3263 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ...                                             tweets\n",
              "0         0  ...             Just happened a terrible car crash    \n",
              "1         2  ...  Heard about #earthquake is different cities, s...\n",
              "2         3  ...  there is a forest fire at spot pond, geese are...\n",
              "3         9  ...       Apocalypse lighting. #Spokane #wildfires    \n",
              "4        11  ...  Typhoon Soudelor kills 28 in China and Taiwan    \n",
              "...     ...  ...                                                ...\n",
              "3258  10861  ...  EARTHQUAKE SAFETY LOS ANGELES Â‰Ã›Ã’ SAFETY FASTE...\n",
              "3259  10865  ...  Storm in RI worse than last hurricane. My city...\n",
              "3260  10868  ...  Green Line derailment in Chicago http://t.co/U...\n",
              "3261  10874  ...  MEG issues Hazardous Weather Outlook (HWO) htt...\n",
              "3262  10875  ...  #CityofCalgary has activated its Municipal Eme...\n",
              "\n",
              "[3263 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-T-TmqSOJyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create sentence and label lists\n",
        "tweets = test_df.tweets.values\n",
        "\n",
        "# clean tweets\n",
        "tweets = [clean(tweet) for tweet in tweets]\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every tweet...\n",
        "for tweet in tweets:\n",
        "    encoded_tweet = tokenizer.encode(tweet, add_special_tokens = True)\n",
        "    input_ids.append(encoded_tweet)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=max_len, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token and 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "# prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeBb-cYeOL-t",
        "colab_type": "code",
        "outputId": "c6c4cc23-05a6-4aa0-b9e7-e8bf4bcec809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions = []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask = batch\n",
        "  \n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy().squeeze().tolist()\n",
        "  # label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions.extend(logits)\n",
        "  # true_labels.append(label_ids)\n",
        "\n",
        "print('\\n DONE.')\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 3,263 test sentences...\n",
            "\n",
            " DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWPraxrpU5Sk",
        "colab_type": "code",
        "outputId": "4e80f399-1eb7-4d4e-e298-65c4d1aa3bef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred_labels = np.argmax(predictions, axis=1).flatten()\n",
        "print(pred_labels)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 ... 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo9l4GNTepfJ",
        "colab_type": "code",
        "outputId": "fcc491b4-07b3-44e9-944a-db44a4e7ddab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# just being paranoid, making sure that it's the same as the number of inputs for prediction\n",
        "print(len(pred_labels))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7XpjUYbSeNu",
        "colab_type": "code",
        "outputId": "a314151d-1e2a-454b-f6bb-57a77f2e2a7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# get a df that is of the required format \n",
        "submission_df = pd.read_csv(\"/content/sample_submission.csv\")\n",
        "submission_df[\"target\"] = pred_labels\n",
        "submission_df"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>10861</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3259</th>\n",
              "      <td>10865</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>10868</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>10874</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>10875</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3263 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  target\n",
              "0         0       1\n",
              "1         2       1\n",
              "2         3       1\n",
              "3         9       1\n",
              "4        11       1\n",
              "...     ...     ...\n",
              "3258  10861       0\n",
              "3259  10865       1\n",
              "3260  10868       1\n",
              "3261  10874       1\n",
              "3262  10875       1\n",
              "\n",
              "[3263 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dfAK5tySnTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_df.to_csv('/content/submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVJLO6rl5eqe",
        "colab_type": "text"
      },
      "source": [
        "After submitting, my score came in at 0.82413 (previously 0.80061), which puts me at the top 27% (previously 44%). Still way to go but I am seeing some improvement. :) Next step would be data augmentation. Will update this space with either a new script/notebook when I'm done. Till then. "
      ]
    }
  ]
}